{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d6be04",
   "metadata": {},
   "source": [
    "### Prepare Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb57070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ocifs\n",
    "import pandas as pd\n",
    "\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "from ads import set_auth\n",
    "\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "from ads.common.model_metadata import (MetadataCustomCategory,\n",
    "                                       UseCaseType,\n",
    "                                       Framework)\n",
    "\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6429582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddccd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare artifacts directory\n",
    "\n",
    "PATH_ARTEFACT = \"/home/datascience/model-files\"\n",
    "MODEL_FILE = 'model.pkl'\n",
    "\n",
    "PATH_NAME = PATH_ARTEFACT + \"/\" + MODEL_FILE\n",
    "\n",
    "# the model pickle file have been saved by catboost1 NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232a661a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ADS:As force_overwrite is set to True, all the existing files in the /home/datascience/model-files will be removed\n",
      "WARNING:ADS:Taxonomy metadata was not extracted. To auto-populate taxonomy metadata the model must be provided. Pass the model as a parameter to .prepare_generic_model(model=model, usecase_type=UseCaseType.REGRESSION). Alternative way is using atifact.populate_metadata(model=model, usecase_type=UseCaseType.REGRESSION).\n",
      "INFO:ads.common:To auto-extract taxonomy metadata the model must be provided. Supported models: automl, keras, lightgbm, pytorch, sklearn, tensorflow, and xgboost.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here I can specify some info that will be saved in Model Catalog\n",
    "#\n",
    "my_inf_conda_env = 'oci://conda_envs@fr95jjtqbdhh/conda_environments/gpu/tf26_catboost/1.0/tf26_catboostv1_0'\n",
    "\n",
    "artifact = prepare_generic_model(PATH_ARTEFACT, force_overwrite=True, data_science_env=False, \n",
    "                                 use_case_type=UseCaseType.BINARY_CLASSIFICATION,\n",
    "                                 inference_conda_env=my_inf_conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03043387",
   "metadata": {},
   "source": [
    "### Qui customizziamo score.py, aggiungendo logging etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef72d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/datascience/model-files/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PATH_ARTEFACT}/score.py\n",
    "\n",
    "#\n",
    "# customize and save score.py\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import catboost as cat\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import logging \n",
    "\n",
    "# logging configuration - OPTIONAL \n",
    "logging.basicConfig(format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger_pred = logging.getLogger('model-prediction')\n",
    "logger_pred.setLevel(logging.INFO)\n",
    "logger_feat = logging.getLogger('input-features')\n",
    "logger_feat.setLevel(logging.INFO)\n",
    "\n",
    "# it is loaded in load_model()\n",
    "model_file_name = \"model.pkl\"\n",
    "\n",
    "# to enable/disable detailed logging\n",
    "DEBUG = True\n",
    "\n",
    "\"\"\"\n",
    "   Inference script. This script is used for prediction by scoring server when schema is known.\n",
    "\"\"\"\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Loads model from the serialized format\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:  a model instance on which predict API can be invoked\n",
    "    \"\"\"\n",
    "    \n",
    "    model_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    contents = os.listdir(model_dir)\n",
    "    \n",
    "    # Load the model from the model_dir using the appropriate loader\n",
    "    \n",
    "    if model_file_name in contents:\n",
    "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), model_file_name), \"rb\") as file:\n",
    "            model = pickle.load(file) \n",
    "            logger_pred.info(\"Loaded model...\")\n",
    "       \n",
    "    else:\n",
    "        raise Exception('{0} is not found in model directory {1}'.format(model_file_name, model_dir))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def preprocess_data(x):\n",
    "    logger_pred.info(\"Eventually preprocessing and adding features...\")\n",
    "    \n",
    "    return x\n",
    "\n",
    "def predict(data, model=load_model()) -> dict:\n",
    "    \"\"\"\n",
    "    Returns prediction given the model and data to predict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model instance returned by load_model API\n",
    "    data: Data format as expected by the predict API of the core estimator. For eg. in case of sckit models it could be numpy array/List of list/Panda DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: Output from scoring server\n",
    "        Format: { 'prediction': output from `model.predict` method }\n",
    "\n",
    "    \"\"\"\n",
    "    # model contains the model and the scaler\n",
    "    logger_pred.info(\"In predict...\")\n",
    "    \n",
    "    # some check\n",
    "    assert model is not None, \"Model is not loaded\"\n",
    "    \n",
    "    x = pd.read_json(io.StringIO(data)).values\n",
    "    \n",
    "    if DEBUG:\n",
    "        logger_feat.info(\"Logging features\")\n",
    "        logger_feat.info(x)\n",
    "    \n",
    "    # preprocess data (for example normalize features)\n",
    "    x = preprocess_data(x)\n",
    "\n",
    "    logger_pred.info(\"Invoking model......\")\n",
    "    \n",
    "    preds = model.predict_proba(x)\n",
    "    \n",
    "    # rounded\n",
    "    preds = np.round(preds[:, 1], 4)\n",
    "    preds = preds.tolist()\n",
    "    \n",
    "    logger_pred.info(\"Logging predictions\")\n",
    "    logger_pred.info(preds)\n",
    "    \n",
    "    return { 'prediction': preds }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51af842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ads.common:{\n",
      "  \"git_branch\": \"main\",\n",
      "  \"git_commit\": \"02f7a2879cf021a04dca242bad0b9a201a897d76\",\n",
      "  \"repository_url\": \"https://github.com/luigisaetta/catboost-employee-attrition.git\",\n",
      "  \"script_dir\": \"/home/datascience/model-files\",\n",
      "  \"training_id\": \"ocid1.datasciencenotebooksession.oc1.eu-frankfurt-1.amaaaaaa7egirmqaub6qzqhkayw5p6wbtz4ttoyl6gbnzfmh6cyvw2tv6hvq\",\n",
      "  \"training_script\": \"None\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_9d414603-f620-4b86-8517-94dd5d0674e3.zip\n"
     ]
    }
   ],
   "source": [
    "catalog_entry = artifact.save(display_name='model-catboost20', description='A model for Employee Attrition using catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af99f4e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07256d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_object_storage(prefix, file_name):\n",
    "    # get access to OSS as an fs\n",
    "    # config={} assume resource_principal auth\n",
    "    fs = ocifs.OCIFileSystem(config={})\n",
    "    \n",
    "    FILE_PATH = prefix + file_name\n",
    "    \n",
    "    # reading data from Object Storage\n",
    "    with fs.open(FILE_PATH, 'rb') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1bc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"oci://data_input@fr95jjtqbdhh/\"\n",
    "FILE_NAME = \"orcl_attrition.csv\"\n",
    "\n",
    "# see in functions above\n",
    "data_orig = read_from_object_storage(prefix=PREFIX, file_name=FILE_NAME)\n",
    "\n",
    "# some columns are not needed. This is the list of columns that will be used\n",
    "my_columns = ['Age', 'Attrition', 'EnvironmentSatisfaction', 'MaritalStatus', 'TravelForWork', 'SalaryLevel', 'JobFunction', 'CommuteLength', 'EducationalLevel', 'EducationField', 'MonthlyIncome', \n",
    "              'OverTime', 'StockOptionLevel', 'TrainingTimesLastYear', 'YearsSinceLastPromotion', 'WorkLifeBalance']\n",
    "\n",
    "# dataset filtrato eliminando le colonne non necessarie\n",
    "data = data_orig[my_columns]\n",
    "\n",
    "# tipologie di features e colonne\n",
    "TARGET = 'Attrition'\n",
    "\n",
    "# automatizziamo !!!\n",
    "all_columns = sorted(my_columns)\n",
    "features = sorted(list(set(all_columns) - set([TARGET])))\n",
    "\n",
    "x_data = data[features]\n",
    "y_data = data[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f07e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use for test data from START to END\n",
    "\n",
    "START = 10\n",
    "END = 20\n",
    "\n",
    "x_input = x_data.iloc[START:END].values\n",
    "y_label = y_data.iloc[START:END].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbd0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:model-prediction:Loaded model...\n",
      "INFO:model-prediction:Loaded model...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# add the path of score.py: \n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, PATH_ARTEFACT)\n",
    "\n",
    "from score import load_model, predict\n",
    "\n",
    "# Load the model to memory \n",
    "loaded_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07553456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:model-prediction:In predict...\n",
      "INFO:input-features:Logging features\n",
      "INFO:input-features:[[36 17 'Medical' 'L3' 1 'Software Developer' 'Married' 2426 'No' 3710 1\n",
      "  5 'infrequent' 3 0]\n",
      " [30 16 'Life Sciences' 'L2' 4 'Software Developer' 'Single' 4193 'Yes'\n",
      "  700 0 3 'infrequent' 3 0]\n",
      " [32 27 'Life Sciences' 'L1' 1 'Software Developer' 'Divorced' 2911 'No'\n",
      "  3072 1 1 'infrequent' 2 4]\n",
      " [35 20 'Medical' 'L2' 2 'Software Developer' 'Divorced' 2661 'No' 6172 1\n",
      "  2 'infrequent' 3 1]\n",
      " [29 25 'Life Sciences' 'L3' 3 'Software Developer' 'Single' 2028 'Yes'\n",
      "  472 0 4 'infrequent' 3 0]\n",
      " [30 22 'Life Sciences' 'L4' 2 'Software Developer' 'Divorced' 9980 'No'\n",
      "  6370 1 1 'infrequent' 3 8]\n",
      " [33 6 'Life Sciences' 'L2' 1 'Software Developer' 'Divorced' 3298 'Yes'\n",
      "  1530 2 5 'infrequent' 2 0]\n",
      " [23 17 'Medical' 'L2' 4 'Software Developer' 'Divorced' 2935 'Yes' 5150\n",
      "  2 2 'none' 2 0]\n",
      " [54 3 'Life Sciences' 'L4' 1 'Product Management' 'Married' 15427 'No'\n",
      "  5590 0 3 'infrequent' 3 3]\n",
      " [39 3 'Life Sciences' 'L3' 4 'Software Developer' 'Single' 3944 'Yes'\n",
      "  1700 0 3 'infrequent' 3 1]]\n",
      "INFO:model-prediction:Eventually preprocessing and adding features...\n",
      "INFO:model-prediction:Invoking model......\n",
      "INFO:model-prediction:Logging predictions\n",
      "INFO:model-prediction:[0.215, 0.4864, 0.1949, 0.1424, 0.8115, 0.0973, 0.3988, 0.3068, 0.2332, 0.3079]\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predict(json.dumps(x_input.tolist()), loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1131450",
   "metadata": {},
   "source": [
    "### Ora, testiamo il Model Deployment (REST service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25aa8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last steps to invoke the model deployment REST service\n",
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864b5d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the probs from the deployed model:\n",
      "{'prediction': [0.215, 0.4864, 0.1949, 0.1424, 0.8115, 0.0973, 0.3988, 0.3068, 0.2332, 0.3079]}\n",
      "\n",
      "and these are the labels:\n",
      "['No' 'No' 'No' 'No' 'Yes' 'No' 'No' 'No' 'No' 'No']\n",
      "\n",
      "CPU times: user 644 ms, sys: 2.82 ms, total: 647 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "endpoint = \"https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaa7egirmqax67pw7mc37vjfzj76xxmp7eunvipii76qsld7wvyaxyq/predict\"\n",
    "\n",
    "# again using RP\n",
    "rps = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "# payload goes here\n",
    "body = json.dumps(x_input.tolist()) \n",
    "\n",
    "print(\"These are the probs from the deployed model:\")\n",
    "print(requests.post(endpoint, json=body, auth=rps).json())\n",
    "\n",
    "print()\n",
    "print(\"and these are the labels:\")\n",
    "print(y_label)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28995bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf26_catboostv1_0]",
   "language": "python",
   "name": "conda-env-tf26_catboostv1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
