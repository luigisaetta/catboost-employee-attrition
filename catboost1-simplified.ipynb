{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7672f0",
   "metadata": {},
   "source": [
    "### Employee Attrition using **CatBoost**\n",
    "\n",
    "* L.S, ottobre 2021\n",
    "* gestione delle **feature categoriche**\n",
    "* importanza del **Learning rate**\n",
    "* gestione dataset imbalance tramite **class weights**\n",
    "\n",
    "Questo notebook è semplificato, rispetto alla versione completa (catboost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5112cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading data from Object Storage\n",
    "from utils import read_from_object_storage, my_train_test_split, plot_cm, compute_auc\n",
    "from utils import compute_prec_rec, compute_accuracy\n",
    "\n",
    "from ads import set_auth\n",
    "\n",
    "# usero' catboost\n",
    "import catboost as cat\n",
    "\n",
    "# per la confusion matrix ed altre metriche uso sklearn\n",
    "# in utils.py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# grafici\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362cefc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this way we enable access to Object Storage and don't need to provide API keys\n",
    "# OCI admin must have set-up a dynamic group for Notebooks, with proper policy\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937b84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function and globals\n",
    "# GLOBALS\n",
    "FIGSIZE = (9, 6)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# additional print\n",
    "DEBUG = 0\n",
    "\n",
    "#set the tracking uri to log runs on a tracking server\n",
    "TRACKING_URI = \"http://150.230.146.100:5000/\"\n",
    "\n",
    "# end globals\n",
    "\n",
    "#\n",
    "# Utility functions in utils.py\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee03ac7",
   "metadata": {},
   "source": [
    "### Reading dataset from Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e46ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data from file in Object Storage\n",
    "PREFIX = \"oci://data_input@fr95jjtqbdhh/\"\n",
    "FILE_NAME = \"orcl_attrition.csv\"\n",
    "\n",
    "# see in functions above\n",
    "data_orig = read_from_object_storage(prefix=PREFIX, file_name=FILE_NAME)\n",
    "\n",
    "# some columns are not needed. This is the list of columns that will be used\n",
    "my_columns = ['Age', 'Attrition', 'EnvironmentSatisfaction', 'MaritalStatus', 'TravelForWork', 'SalaryLevel', 'JobFunction', 'CommuteLength', 'EducationalLevel', 'EducationField', 'MonthlyIncome', \n",
    "              'OverTime', 'StockOptionLevel', 'TrainingTimesLastYear', 'YearsSinceLastPromotion', 'WorkLifeBalance']\n",
    "\n",
    "# dataset filtrato eliminando le colonne non necessarie\n",
    "data = data_orig[my_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c9be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonna Target: Attrition\n",
      "\n",
      "Tutte le features: ['Age', 'CommuteLength', 'EducationField', 'EducationalLevel', 'EnvironmentSatisfaction', 'JobFunction', 'MaritalStatus', 'MonthlyIncome', 'OverTime', 'SalaryLevel', 'StockOptionLevel', 'TrainingTimesLastYear', 'TravelForWork', 'WorkLifeBalance', 'YearsSinceLastPromotion'] 15\n",
      "\n",
      "Colonne categorical: ['Age', 'CommuteLength', 'EducationField', 'EducationalLevel', 'EnvironmentSatisfaction', 'JobFunction', 'MaritalStatus', 'OverTime', 'StockOptionLevel', 'TrainingTimesLastYear', 'TravelForWork', 'WorkLifeBalance', 'YearsSinceLastPromotion'] 13\n",
      "\n",
      "Colonne numeriche: ['MonthlyIncome', 'SalaryLevel'] 2\n",
      "\n",
      "Numero totale di campioni: 1470\n",
      "Numero di campioni nel TRAIN SET: 1323\n",
      "Numero di campioni nel TEST SET: 147\n"
     ]
    }
   ],
   "source": [
    "# tipologie di features e colonne\n",
    "TARGET = 'Attrition'\n",
    "\n",
    "# automatizziamo !!!\n",
    "all_columns = sorted(data.columns)\n",
    "features = sorted(list(set(all_columns) - set([TARGET])))\n",
    "\n",
    "# per decidere, guarda statistiche dal Notebook EDA1\n",
    "cat_columns = sorted(['Age', 'CommuteLength','EnvironmentSatisfaction','MaritalStatus', 'TravelForWork', 'JobFunction', \n",
    "                      'EducationalLevel', 'EducationField', 'OverTime', \n",
    "                      'StockOptionLevel', 'TrainingTimesLastYear',\n",
    "                      'YearsSinceLastPromotion', 'WorkLifeBalance'])\n",
    "\n",
    "\n",
    "# colonne numeriche, continue (tutte le altre)\n",
    "num_columns = sorted(list(set(all_columns) - set(cat_columns) - set([TARGET])))\n",
    "\n",
    "print('Colonna Target:', TARGET)\n",
    "print()\n",
    "print('Tutte le features:', features, len(features))\n",
    "print()\n",
    "print('Colonne categorical:', cat_columns, len(cat_columns))\n",
    "print()\n",
    "print('Colonne numeriche:', num_columns, len(num_columns))\n",
    "\n",
    "\n",
    "# split TRAIN, TEST\n",
    "# shuffle prima dello split TRAIN, TEST\n",
    "FRAC = 0.90\n",
    "\n",
    "data_train, data_test = my_train_test_split(data, frac=FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb59f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NameError: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# separo X (features) ed y (target)\n",
    "x_train = data_train[features]\n",
    "y_train = data_train[TARGET]\n",
    "\n",
    "x_test = data_test[features]\n",
    "y_test = data_test[TARGET]\n",
    "\n",
    "# encode labels as 0, 1\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit the encoder\n",
    "le.fit(y_train.values)\n",
    "\n",
    "# encode train and test\n",
    "y_train = le.transform(y_train.values)\n",
    "y_test = le.transform(y_test.values)\n",
    "\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(x_train.columns) if col in cat_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23699062",
   "metadata": {},
   "source": [
    "### First run, without class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c79575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NameError: name 'cat_columns_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# First: try without addressing data imbalance\n",
    "\n",
    "params = {'iterations':900,\n",
    "          'learning_rate':0.005,\n",
    "          'depth':10\n",
    "         }\n",
    "\n",
    "model = cat.CatBoostClassifier()\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(x_train, y_train, cat_columns_idxs, verbose=False, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and register results\n",
    "auc = compute_auc(model, x_test, y_test)\n",
    "print('AUC computed on the test set is:', auc)\n",
    "\n",
    "prec, rec = compute_prec_rec(model, x_test, y_test)\n",
    "print('precision and recall computed on the test set are:', 'prec:', prec, 'rec:', rec)\n",
    "\n",
    "acc = compute_accuracy(model, x_test, y_test)\n",
    "print('Accuracy on test set is:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf40a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NameError: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cm(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa789f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebe582",
   "metadata": {},
   "source": [
    "### Second run, with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# to address data imbalance\n",
    "class_weights = dict({0:1, 1:5.5})\n",
    "\n",
    "params = {'iterations':900,\n",
    "          'learning_rate':0.005,\n",
    "          'depth':10,\n",
    "          'class_weights':class_weights\n",
    "         }\n",
    "\n",
    "model = cat.CatBoostClassifier()\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(x_train, y_train, cat_columns_idxs, verbose=False, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e11e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and register results\n",
    "auc = compute_auc(model, x_test, y_test)\n",
    "print('AUC computed on the test set is:', auc)\n",
    "\n",
    "prec, rec = compute_prec_rec(model, x_test, y_test)\n",
    "print('precision and recall computed on the test set are:', 'prec:', prec, 'rec:', rec)\n",
    "\n",
    "acc = compute_accuracy(model, x_test, y_test)\n",
    "print('Accuracy on test set is:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d1f85",
   "metadata": {},
   "source": [
    "### Evaluate confusion matrix on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c'è un certo overfitting...\n",
    "plot_cm(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8148a",
   "metadata": {},
   "source": [
    "### Global explaination using feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eXplainability: Feature importance\n",
    "\n",
    "plt.figure(figsize = FIGSIZE)\n",
    "plt.grid(True)\n",
    "sns.barplot(x = model.get_feature_importance(), y = features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceedf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-tf26_catboostv1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
